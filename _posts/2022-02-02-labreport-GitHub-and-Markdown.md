---
layout: post
title: Lab 01 - Understanding GitHub & Markdown
subtitle: Reflections & Goals
gh-repo: daattali/beautiful-jekyll
gh-badge: [star, fork, follow]
tags: [test]
comments: true
---
 

## (1) Process
### Getting to know GitHub
Prior to this lab, I had used GitHub only once before. I have vague memory of the specifics of this interaction, but I know I used it either to test or compare lines of codes. Therefore, I approached the lab with basic understanding of what GitHub could be used for, but had not used it in a personalized way. Getting to GitHub and making an account was fairly straightforward. And while editing the site on my own has definitely been a process of trial and error, each step we walked through during the in-class portion of the lab was very clarifying.

Now that I have my webpage set up and was able to follow the steps in our in-class lab sessions, I am playing with the desktop versions of GitHub and markdown on my computer. To do this, I have downloaded GitHub Desktop and Ulysses (to write in markdown). I chose Ulysses both because I have heard it mentioned in other contexts and… well… its Joyce connection is fun, even if insignificant. The next step from here will be learning to successfully upload from GitHub Desktop. 

## (2) Course Goals
My goals for this course are not highly specific, but broadly, I would like to (1) acquire better research skills, (2) expand my competency in data representation, and (3) think more seriously about the ethical implications of building, sharing, and repurposing data. I have had some great professors in the ISC/DH realm over the years and I have dabbled in a lot of different DH tools at the surface level, but I have not really mastered any techniques directly applicable to my work now. That is, I have some superficial understanding of what various programs and languages *do*, but I have little knowledge (and/or) memory of how to use them.

1. At the most basic level, I could definitely become more proficient in using the basic tools required to build datasets (namely, Excel and its functions!). As an antecedent to this step, though, I also would like to become more efficient in looking for patterns across multiple texts and genres. That is, before I can build a dataset, I need to become better at text mining. As Rosenberg shows, there may be no *quick* fix or technical skill to facilitate this latter process, but I hope this class will help me think a bit more *like* a data scientist when faced with questions of pattern and correlation.

2. At a more complicated level, I am really fascinated by interactive story-telling and representation of physical space. I think it would be really useful to be able to layer existing fiction texts portraying, for example, certain states of illness or disability, with actual information about the socio-historical genesis and treatment of said conditions. Again, while I don’t expect this course to give me the precise skills to accomplish this type of data immersion, I hope it generates ideas about where I might start.

3. Finally, I am fascinated by the implications and boundaries of data collection. Via my *smart* medical devices, I constantly interact with numerical data for survival. This data—that is, my blood sugar levels (and the corresponding metadata), how much insulin I use, and when I do and do not have the device(s) on and activated—is always shared, if only to the suppliers of each device, and thus not entirely mine. This situation does not make me unique (outside of my privilege to have access to these life-saving devices in the first place), as we are all subject to the process of data collection(/extraction) to varying degrees. However, perhaps because of my heightened awareness to the enacted erasure of boundaries between private, public, and institutional data, I am interested in gaining a better understanding of how, on a larger scale, this process of data extraction and regurgitation is negotiated between ISAs and individuals and how it informs cultural materials.

